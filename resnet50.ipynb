{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Oct 21 08:51:45 2020\n",
    "\n",
    "@author: LiuQi\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from keras import layers, optimizers, models\n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import *    \n",
    "from keras.models import Model,load_model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "import heapq\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 4\n",
    "\n",
    "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())                                                     #平铺层\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(n, activation='softmax'))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-4), metrics=['acc'])\n",
    "\n",
    "category = '贵妇'\n",
    "basic_path = f'E:/jupyter program/Social image/{category}/classify'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1940 images belonging to 4 classes.\n",
      "Found 487 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True, )\n",
    "\n",
    "test_datagen = ImageDataGenerator()\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "\tf'{basic_path}/train',\n",
    "\ttarget_size=(224, 224),\n",
    "\tbatch_size=16,\n",
    "    \n",
    "\tclass_mode='categorical')\n",
    " \n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "\tf'{basic_path}/validation',\n",
    "\ttarget_size=(224, 224),\n",
    "\tbatch_size=16,\n",
    "\tclass_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "122/122 [==============================] - 214s 2s/step - loss: 2.8934 - acc: 0.6297 - val_loss: 0.9558 - val_acc: 0.7844\n",
      "Epoch 2/15\n",
      "122/122 [==============================] - 196s 2s/step - loss: 0.6097 - acc: 0.8353 - val_loss: 0.5254 - val_acc: 0.8686\n",
      "Epoch 3/15\n",
      "122/122 [==============================] - 191s 2s/step - loss: 0.4502 - acc: 0.8891 - val_loss: 0.4224 - val_acc: 0.9014\n",
      "Epoch 4/15\n",
      "122/122 [==============================] - 186s 2s/step - loss: 0.3983 - acc: 0.9028 - val_loss: 0.4181 - val_acc: 0.9076\n",
      "Epoch 5/15\n",
      "122/122 [==============================] - 185s 2s/step - loss: 0.3020 - acc: 0.9168 - val_loss: 0.7038 - val_acc: 0.8994\n",
      "Epoch 6/15\n",
      "122/122 [==============================] - 184s 2s/step - loss: 0.3001 - acc: 0.9351 - val_loss: 0.3243 - val_acc: 0.9281\n",
      "Epoch 7/15\n",
      "122/122 [==============================] - 184s 2s/step - loss: 0.2984 - acc: 0.9348 - val_loss: 0.6102 - val_acc: 0.8953\n",
      "Epoch 8/15\n",
      "122/122 [==============================] - 183s 2s/step - loss: 0.3060 - acc: 0.9307 - val_loss: 0.6242 - val_acc: 0.8973\n",
      "Epoch 9/15\n",
      "122/122 [==============================] - 185s 2s/step - loss: 0.2643 - acc: 0.9381 - val_loss: 0.5390 - val_acc: 0.9097\n",
      "Epoch 10/15\n",
      "122/122 [==============================] - 185s 2s/step - loss: 0.2878 - acc: 0.9488 - val_loss: 1.1755 - val_acc: 0.8645\n",
      "Epoch 11/15\n",
      "122/122 [==============================] - 186s 2s/step - loss: 0.2335 - acc: 0.9530 - val_loss: 0.5901 - val_acc: 0.9199\n",
      "Epoch 12/15\n",
      "122/122 [==============================] - 188s 2s/step - loss: 0.2532 - acc: 0.9520 - val_loss: 0.6145 - val_acc: 0.9261\n",
      "Epoch 13/15\n",
      "122/122 [==============================] - 182s 1s/step - loss: 0.2477 - acc: 0.9545 - val_loss: 0.6711 - val_acc: 0.9220\n",
      "Epoch 14/15\n",
      "122/122 [==============================] - 184s 2s/step - loss: 0.2436 - acc: 0.9578 - val_loss: 0.9104 - val_acc: 0.9117\n",
      "Epoch 15/15\n",
      "122/122 [==============================] - 183s 1s/step - loss: 0.3018 - acc: 0.9471 - val_loss: 0.6270 - val_acc: 0.9281\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "\ttrain_generator,\n",
    "# \tsteps_per_epoch=200,\n",
    "\tepochs=15,\n",
    "\tvalidation_data=validation_generator,\n",
    "# \tvalidation_steps=24,\n",
    "\tverbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def plot_curve(history):\n",
    "#     acc = history.history['acc']\n",
    "#     val_acc = history.history['val_acc']\n",
    "#     loss = history.history['loss']\n",
    "#     val_loss = history.history['val_loss']\n",
    "    \n",
    "#     epochs = range(1,len(acc)+1)\n",
    "    \n",
    "#     plt.plot(epochs,acc,'bo',label='Training acc')\n",
    "#     plt.plot(epochs,val_acc,'b',label='Validation acc')\n",
    "#     plt.title('Training and validation accuracy')\n",
    "#     plt.legend()\n",
    "    \n",
    "#     plt.figure()\n",
    "#     plt.plot(epochs,loss,'bo',label='Training loss')\n",
    "#     plt.plot(epochs,val_loss,'b',label='Validation loss')\n",
    "#     plt.title('Training and validation loss')\n",
    "#     plt.legend()\n",
    "    \n",
    "# plot_curve(history)\n",
    "\n",
    "\n",
    "# test_generator = test_datagen.flow_from_directory(\n",
    "#     r'C:\\Users\\liuqi\\Desktop\\page_segmentation\\Unilever\\test',\n",
    "# \ttarget_size=(224, 224),\n",
    "# \tbatch_size=16,\n",
    "# \tclass_mode='binary')\n",
    "# test_loss, test_acc = model.evaluate_generator(test_generator, steps=16)\n",
    "# print('test acc:', test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型保存\n",
    "model.save_weights(f'{category}_weight.h5')\n",
    "model.save(f'{category}.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dict(zip(range(n),(subpath.split('\\\\')[-1] for subpath in glob.glob(f'{basic_path}/raw image/*'))))\n",
    "\n",
    "# 模型读取及预测\n",
    "def append_seg(filename,seg,prob):\n",
    "    # path = os.path.dirname(filename)\n",
    "    name = os.path.basename(filename)\n",
    "    name, ext = os.path.splitext(name)\n",
    "    # name = f\"{name.split('_')[0]}_{name.split('_')[1]}\"\n",
    "    return f\"{basic_path}/result/{seg}/{prob}_{name}{ext}\"\n",
    "\n",
    "for subpath in glob.glob(f'{basic_path}/raw image/*'):\n",
    "    j = subpath.split('\\\\')[-1]\n",
    "    if not os.path.exists(f'{basic_path}/result/{j}'):\n",
    "       os.makedirs(f'{basic_path}/result/{j}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(f'{category}.h5')\n",
    "target = f'{basic_path}/use image'\n",
    "for subpath in glob.glob(f'{target}/*'):\n",
    "    for im in glob.glob(f'{subpath}/*'):\n",
    "#         try:\n",
    "            img = load_img(im,target_size=(224, 224))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            prob = int(heapq.nlargest(1,model.predict(img).tolist()[0])[0]*10)\n",
    "            segment = np.argmax(model.predict(img), axis=-1)[0]\n",
    "            new_name = append_seg(im,dic[segment],prob)\n",
    "            os.rename(im, new_name)\n",
    "#         except:\n",
    "#             print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = '贵妇'\n",
    "basic_path = f'E:/jupyter program/Social image/{category}/classify'\n",
    "model = load_model(f'{category}.h5')\n",
    "target = f'{basic_path}/use image'\n",
    "for subpath in glob.glob(f'{target}/*'):\n",
    "    for im in glob.glob(f'{subpath}/*'):\n",
    "#         try:\n",
    "            img = load_img(im,target_size=(224, 224))\n",
    "            img = image.img_to_array(img)\n",
    "            img = np.expand_dims(img, axis=0)\n",
    "            prob = int(heapq.nlargest(1,model.predict(img).tolist()[0])[0]*10)\n",
    "            segment = np.argmax(model.predict(img), axis=-1)[0]\n",
    "            new_name = append_seg(im,dic[segment],prob)\n",
    "            os.rename(im, new_name)\n",
    "#         except:\n",
    "#             print(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1419699857981184839\n",
      "]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version of TF: 2.4.1\n",
      "False\n",
      "GPU devices:\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import timeit\n",
    "\n",
    "\n",
    "\n",
    "print('version of TF:',tf.__version__)\n",
    "\n",
    "print(tf.test.is_gpu_available())\n",
    "\n",
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "print('GPU devices:')\n",
    "\n",
    "print(gpus)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From E:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "Device mapping: no known devices.\n",
      "[[22. 28.]\n",
      " [49. 64.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "# Creates a graph.\n",
    "a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "c = tf.matmul(a, b)\n",
    "# Creates a session with log_device_placement set to True.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# Runs the op.\n",
    "print(sess.run(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
